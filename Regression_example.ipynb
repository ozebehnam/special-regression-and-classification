{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ba0f558",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6867c170",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, train_labels), (test_data, test_labels) = tf.keras.datasets.boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33ab141a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 1)\n",
      "(102, 1)\n"
     ]
    }
   ],
   "source": [
    "train_labels = np.reshape(train_labels, (-1,1))\n",
    "test_labels = np.reshape(test_labels, (-1,1))\n",
    "print(train_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "324ebd32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([6.3200e-03, 0.0000e+00, 4.6000e-01, 0.0000e+00, 3.8500e-01,\n",
       "        3.5610e+00, 2.9000e+00, 1.1296e+00, 1.0000e+00, 1.8800e+02,\n",
       "        1.2600e+01, 3.2000e-01, 1.7300e+00]),\n",
       " array([ 88.9762, 100.    ,  27.74  ,   1.    ,   0.871 ,   8.725 ,\n",
       "        100.    ,  10.7103,  24.    , 711.    ,  22.    , 396.9   ,\n",
       "         37.97  ]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.min(axis=0), train_data.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b4d91ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c519f533",
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a06b685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm_scaler.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a215c4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = mm_scaler.transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9439880b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.min(axis=0), train_data.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20b64e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.0, 50.0, 5.6, 50.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.min(), train_labels.max(), test_labels.min(), test_labels.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca40e016",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 7.63179629e-05,  0.00000000e+00,  2.78592375e-02,  0.00000000e+00,\n",
       "         1.44032922e-02,  2.55422153e-01,  3.19258496e-02,  3.50600687e-02,\n",
       "         0.00000000e+00, -1.91204589e-03,  4.25531915e-02,  6.13495386e-02,\n",
       "         5.24282561e-03]),\n",
       " array([0.28144109, 0.9       , 1.        , 1.        , 1.        ,\n",
       "        1.01065066, 1.        , 1.14781801, 1.        , 1.        ,\n",
       "        0.91489362, 1.        , 0.83498896]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = mm_scaler.transform(test_data)\n",
    "test_data.min(axis=0), test_data.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd53d0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_labels / 50.\n",
    "test_labels = test_labels / 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e98b8ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1, 1.0, 0.11199999999999999, 1.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.min(), train_labels.max(), test_labels.min(), test_labels.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2af42951",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "933f5239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 13)]              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 70        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 440\n",
      "Trainable params: 440\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input((13, ))\n",
    "\n",
    "hidden_layer_1 = Dense(units=13, activation='relu')(input_layer)\n",
    "\n",
    "hidden_layer_2 = Dense(units=13, activation='relu')(hidden_layer_1)\n",
    "\n",
    "hidden_layer_3 = Dense(units=5, activation='relu')(hidden_layer_2)\n",
    "\n",
    "output_layer = Dense(units=1, activation='sigmoid')(hidden_layer_3)\n",
    "\n",
    "regression_model = Model(input_layer, output_layer)\n",
    "\n",
    "regression_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73803ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(train_data[0], train_labels[0])\n",
    "#random_first_predict = regression_model(np.reshape(train_data[0], (1, 13)))\n",
    "#random_first_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44e26f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(train_data[1], train_labels[1])\n",
    "#random_second_predict = regression_model(np.reshape(train_data[1], (1, 13)))\n",
    "#random_second_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dda5b606",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(train_data[3], train_labels[3])\n",
    "#random_third_predict = regression_model(np.reshape(train_data[3], (1, 13)))\n",
    "#random_third_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d417060e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a51d44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', patience=100, mode='min', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d55ed484",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56aecc80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0398 - val_loss: 0.0310\n",
      "Epoch 2/600\n",
      "51/51 [==============================] - 0s 743us/step - loss: 0.0317 - val_loss: 0.0271\n",
      "Epoch 3/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0260 - val_loss: 0.0207\n",
      "Epoch 4/600\n",
      "51/51 [==============================] - 0s 703us/step - loss: 0.0195 - val_loss: 0.0162\n",
      "Epoch 5/600\n",
      "51/51 [==============================] - 0s 703us/step - loss: 0.0152 - val_loss: 0.0139\n",
      "Epoch 6/600\n",
      "51/51 [==============================] - 0s 703us/step - loss: 0.0126 - val_loss: 0.0133\n",
      "Epoch 7/600\n",
      "51/51 [==============================] - 0s 703us/step - loss: 0.0109 - val_loss: 0.0120\n",
      "Epoch 8/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0090 - val_loss: 0.0107\n",
      "Epoch 9/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0081 - val_loss: 0.0112\n",
      "Epoch 10/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0075 - val_loss: 0.0092\n",
      "Epoch 11/600\n",
      "51/51 [==============================] - 0s 664us/step - loss: 0.0068 - val_loss: 0.0099\n",
      "Epoch 12/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0064 - val_loss: 0.0089\n",
      "Epoch 13/600\n",
      "51/51 [==============================] - 0s 704us/step - loss: 0.0058 - val_loss: 0.0091\n",
      "Epoch 14/600\n",
      "51/51 [==============================] - 0s 695us/step - loss: 0.0055 - val_loss: 0.0086\n",
      "Epoch 15/600\n",
      "51/51 [==============================] - 0s 762us/step - loss: 0.0060 - val_loss: 0.0093\n",
      "Epoch 16/600\n",
      "51/51 [==============================] - 0s 742us/step - loss: 0.0053 - val_loss: 0.0081\n",
      "Epoch 17/600\n",
      "51/51 [==============================] - 0s 742us/step - loss: 0.0050 - val_loss: 0.0091\n",
      "Epoch 18/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0049 - val_loss: 0.0085\n",
      "Epoch 19/600\n",
      "51/51 [==============================] - 0s 664us/step - loss: 0.0047 - val_loss: 0.0082\n",
      "Epoch 20/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0047 - val_loss: 0.0086\n",
      "Epoch 21/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0044 - val_loss: 0.0100\n",
      "Epoch 22/600\n",
      "51/51 [==============================] - 0s 700us/step - loss: 0.0044 - val_loss: 0.0088\n",
      "Epoch 23/600\n",
      "51/51 [==============================] - 0s 703us/step - loss: 0.0043 - val_loss: 0.0095\n",
      "Epoch 24/600\n",
      "51/51 [==============================] - 0s 704us/step - loss: 0.0043 - val_loss: 0.0082\n",
      "Epoch 25/600\n",
      "51/51 [==============================] - 0s 677us/step - loss: 0.0040 - val_loss: 0.0090\n",
      "Epoch 26/600\n",
      "51/51 [==============================] - 0s 704us/step - loss: 0.0041 - val_loss: 0.0091\n",
      "Epoch 27/600\n",
      "51/51 [==============================] - 0s 769us/step - loss: 0.0040 - val_loss: 0.0085\n",
      "Epoch 28/600\n",
      "51/51 [==============================] - 0s 664us/step - loss: 0.0038 - val_loss: 0.0095\n",
      "Epoch 29/600\n",
      "51/51 [==============================] - 0s 704us/step - loss: 0.0038 - val_loss: 0.0080\n",
      "Epoch 30/600\n",
      "51/51 [==============================] - 0s 671us/step - loss: 0.0037 - val_loss: 0.0084\n",
      "Epoch 31/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0039 - val_loss: 0.0087\n",
      "Epoch 32/600\n",
      "51/51 [==============================] - 0s 704us/step - loss: 0.0036 - val_loss: 0.0085\n",
      "Epoch 33/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0036 - val_loss: 0.0091\n",
      "Epoch 34/600\n",
      "51/51 [==============================] - 0s 704us/step - loss: 0.0036 - val_loss: 0.0079\n",
      "Epoch 35/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0035 - val_loss: 0.0084\n",
      "Epoch 36/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0037 - val_loss: 0.0080\n",
      "Epoch 37/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0036 - val_loss: 0.0081\n",
      "Epoch 38/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0034 - val_loss: 0.0088\n",
      "Epoch 39/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0034 - val_loss: 0.0093\n",
      "Epoch 40/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0034 - val_loss: 0.0081\n",
      "Epoch 41/600\n",
      "51/51 [==============================] - 0s 664us/step - loss: 0.0037 - val_loss: 0.0095\n",
      "Epoch 42/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0034 - val_loss: 0.0094\n",
      "Epoch 43/600\n",
      "51/51 [==============================] - 0s 664us/step - loss: 0.0034 - val_loss: 0.0084\n",
      "Epoch 44/600\n",
      "51/51 [==============================] - 0s 704us/step - loss: 0.0034 - val_loss: 0.0081\n",
      "Epoch 45/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0033 - val_loss: 0.0080\n",
      "Epoch 46/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0033 - val_loss: 0.0086\n",
      "Epoch 47/600\n",
      "51/51 [==============================] - 0s 704us/step - loss: 0.0032 - val_loss: 0.0093\n",
      "Epoch 48/600\n",
      "51/51 [==============================] - 0s 703us/step - loss: 0.0034 - val_loss: 0.0082\n",
      "Epoch 49/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0033 - val_loss: 0.0085\n",
      "Epoch 50/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0031 - val_loss: 0.0079\n",
      "Epoch 51/600\n",
      "51/51 [==============================] - 0s 664us/step - loss: 0.0031 - val_loss: 0.0079\n",
      "Epoch 52/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0031 - val_loss: 0.0083\n",
      "Epoch 53/600\n",
      "51/51 [==============================] - 0s 782us/step - loss: 0.0030 - val_loss: 0.0085\n",
      "Epoch 54/600\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0031 - val_loss: 0.0083\n",
      "Epoch 55/600\n",
      "51/51 [==============================] - 0s 860us/step - loss: 0.0030 - val_loss: 0.0083\n",
      "Epoch 56/600\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0088\n",
      "Epoch 57/600\n",
      "51/51 [==============================] - 0s 782us/step - loss: 0.0031 - val_loss: 0.0089\n",
      "Epoch 58/600\n",
      "51/51 [==============================] - 0s 703us/step - loss: 0.0029 - val_loss: 0.0083\n",
      "Epoch 59/600\n",
      "51/51 [==============================] - 0s 762us/step - loss: 0.0030 - val_loss: 0.0081\n",
      "Epoch 60/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0029 - val_loss: 0.0087\n",
      "Epoch 61/600\n",
      "51/51 [==============================] - 0s 735us/step - loss: 0.0030 - val_loss: 0.0086\n",
      "Epoch 62/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0028 - val_loss: 0.0087\n",
      "Epoch 63/600\n",
      "51/51 [==============================] - 0s 899us/step - loss: 0.0032 - val_loss: 0.0097\n",
      "Epoch 64/600\n",
      "51/51 [==============================] - 0s 721us/step - loss: 0.0030 - val_loss: 0.0092\n",
      "Epoch 65/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0029 - val_loss: 0.0087\n",
      "Epoch 66/600\n",
      "51/51 [==============================] - 0s 704us/step - loss: 0.0028 - val_loss: 0.0080\n",
      "Epoch 67/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0028 - val_loss: 0.0082\n",
      "Epoch 68/600\n",
      "51/51 [==============================] - 0s 782us/step - loss: 0.0028 - val_loss: 0.0093\n",
      "Epoch 69/600\n",
      "51/51 [==============================] - 0s 728us/step - loss: 0.0027 - val_loss: 0.0086\n",
      "Epoch 70/600\n",
      "51/51 [==============================] - 0s 704us/step - loss: 0.0027 - val_loss: 0.0089\n",
      "Epoch 71/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0027 - val_loss: 0.0085\n",
      "Epoch 72/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0027 - val_loss: 0.0084\n",
      "Epoch 73/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0026 - val_loss: 0.0084\n",
      "Epoch 74/600\n",
      "51/51 [==============================] - 0s 762us/step - loss: 0.0027 - val_loss: 0.0086\n",
      "Epoch 75/600\n",
      "51/51 [==============================] - 0s 743us/step - loss: 0.0027 - val_loss: 0.0081\n",
      "Epoch 76/600\n",
      "51/51 [==============================] - 0s 704us/step - loss: 0.0026 - val_loss: 0.0083\n",
      "Epoch 77/600\n",
      "51/51 [==============================] - 0s 704us/step - loss: 0.0025 - val_loss: 0.0091\n",
      "Epoch 78/600\n",
      "51/51 [==============================] - 0s 704us/step - loss: 0.0027 - val_loss: 0.0078\n",
      "Epoch 79/600\n",
      "51/51 [==============================] - 0s 742us/step - loss: 0.0026 - val_loss: 0.0083\n",
      "Epoch 80/600\n",
      "51/51 [==============================] - 0s 762us/step - loss: 0.0025 - val_loss: 0.0084\n",
      "Epoch 81/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 723us/step - loss: 0.0026 - val_loss: 0.0091\n",
      "Epoch 82/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0026 - val_loss: 0.0093\n",
      "Epoch 83/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0025 - val_loss: 0.0088\n",
      "Epoch 84/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0026 - val_loss: 0.0089\n",
      "Epoch 85/600\n",
      "51/51 [==============================] - 0s 703us/step - loss: 0.0027 - val_loss: 0.0085\n",
      "Epoch 86/600\n",
      "51/51 [==============================] - 0s 743us/step - loss: 0.0024 - val_loss: 0.0086\n",
      "Epoch 87/600\n",
      "51/51 [==============================] - 0s 762us/step - loss: 0.0024 - val_loss: 0.0080\n",
      "Epoch 88/600\n",
      "51/51 [==============================] - 0s 762us/step - loss: 0.0024 - val_loss: 0.0083\n",
      "Epoch 89/600\n",
      "51/51 [==============================] - 0s 742us/step - loss: 0.0023 - val_loss: 0.0089\n",
      "Epoch 90/600\n",
      "51/51 [==============================] - 0s 742us/step - loss: 0.0025 - val_loss: 0.0092\n",
      "Epoch 91/600\n",
      "51/51 [==============================] - 0s 762us/step - loss: 0.0029 - val_loss: 0.0088\n",
      "Epoch 92/600\n",
      "51/51 [==============================] - 0s 762us/step - loss: 0.0024 - val_loss: 0.0084\n",
      "Epoch 93/600\n",
      "51/51 [==============================] - 0s 704us/step - loss: 0.0024 - val_loss: 0.0082\n",
      "Epoch 94/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0023 - val_loss: 0.0085\n",
      "Epoch 95/600\n",
      "51/51 [==============================] - 0s 703us/step - loss: 0.0023 - val_loss: 0.0087\n",
      "Epoch 96/600\n",
      "51/51 [==============================] - 0s 781us/step - loss: 0.0023 - val_loss: 0.0085\n",
      "Epoch 97/600\n",
      "51/51 [==============================] - 0s 753us/step - loss: 0.0023 - val_loss: 0.0086\n",
      "Epoch 98/600\n",
      "51/51 [==============================] - 0s 742us/step - loss: 0.0025 - val_loss: 0.0083\n",
      "Epoch 99/600\n",
      "51/51 [==============================] - 0s 704us/step - loss: 0.0024 - val_loss: 0.0084\n",
      "Epoch 100/600\n",
      "51/51 [==============================] - 0s 742us/step - loss: 0.0025 - val_loss: 0.0081\n",
      "Epoch 101/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0024 - val_loss: 0.0085\n",
      "Epoch 102/600\n",
      "51/51 [==============================] - 0s 704us/step - loss: 0.0022 - val_loss: 0.0088\n",
      "Epoch 103/600\n",
      "51/51 [==============================] - 0s 762us/step - loss: 0.0024 - val_loss: 0.0087\n",
      "Epoch 104/600\n",
      "51/51 [==============================] - 0s 742us/step - loss: 0.0024 - val_loss: 0.0086\n",
      "Epoch 105/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0023 - val_loss: 0.0086\n",
      "Epoch 106/600\n",
      "51/51 [==============================] - 0s 743us/step - loss: 0.0023 - val_loss: 0.0080\n",
      "Epoch 107/600\n",
      "51/51 [==============================] - 0s 742us/step - loss: 0.0022 - val_loss: 0.0089\n",
      "Epoch 108/600\n",
      "51/51 [==============================] - 0s 704us/step - loss: 0.0022 - val_loss: 0.0087\n",
      "Epoch 109/600\n",
      "51/51 [==============================] - 0s 743us/step - loss: 0.0024 - val_loss: 0.0086\n",
      "Epoch 110/600\n",
      "51/51 [==============================] - 0s 749us/step - loss: 0.0022 - val_loss: 0.0081\n",
      "Epoch 111/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0023 - val_loss: 0.0082\n",
      "Epoch 112/600\n",
      "51/51 [==============================] - 0s 742us/step - loss: 0.0021 - val_loss: 0.0082\n",
      "Epoch 113/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0023 - val_loss: 0.0086\n",
      "Epoch 114/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0024 - val_loss: 0.0083\n",
      "Epoch 115/600\n",
      "51/51 [==============================] - 0s 743us/step - loss: 0.0023 - val_loss: 0.0082\n",
      "Epoch 116/600\n",
      "51/51 [==============================] - 0s 762us/step - loss: 0.0022 - val_loss: 0.0084\n",
      "Epoch 117/600\n",
      "51/51 [==============================] - 0s 782us/step - loss: 0.0022 - val_loss: 0.0085\n",
      "Epoch 118/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0022 - val_loss: 0.0084\n",
      "Epoch 119/600\n",
      "51/51 [==============================] - 0s 821us/step - loss: 0.0022 - val_loss: 0.0086\n",
      "Epoch 120/600\n",
      "51/51 [==============================] - 0s 938us/step - loss: 0.0021 - val_loss: 0.0082\n",
      "Epoch 121/600\n",
      "51/51 [==============================] - 0s 840us/step - loss: 0.0021 - val_loss: 0.0081\n",
      "Epoch 122/600\n",
      "51/51 [==============================] - 0s 840us/step - loss: 0.0020 - val_loss: 0.0084\n",
      "Epoch 123/600\n",
      "51/51 [==============================] - 0s 919us/step - loss: 0.0021 - val_loss: 0.0084\n",
      "Epoch 124/600\n",
      "51/51 [==============================] - 0s 879us/step - loss: 0.0022 - val_loss: 0.0082\n",
      "Epoch 125/600\n",
      "51/51 [==============================] - 0s 918us/step - loss: 0.0021 - val_loss: 0.0082\n",
      "Epoch 126/600\n",
      "51/51 [==============================] - 0s 899us/step - loss: 0.0021 - val_loss: 0.0087\n",
      "Epoch 127/600\n",
      "51/51 [==============================] - 0s 977us/step - loss: 0.0023 - val_loss: 0.0083\n",
      "Epoch 128/600\n",
      "51/51 [==============================] - 0s 977us/step - loss: 0.0021 - val_loss: 0.0081\n",
      "Epoch 129/600\n",
      "51/51 [==============================] - 0s 821us/step - loss: 0.0021 - val_loss: 0.0084\n",
      "Epoch 130/600\n",
      "51/51 [==============================] - 0s 879us/step - loss: 0.0021 - val_loss: 0.0084\n",
      "Epoch 131/600\n",
      "51/51 [==============================] - 0s 801us/step - loss: 0.0021 - val_loss: 0.0081\n",
      "Epoch 132/600\n",
      "51/51 [==============================] - 0s 899us/step - loss: 0.0021 - val_loss: 0.0079\n",
      "Epoch 133/600\n",
      "51/51 [==============================] - 0s 879us/step - loss: 0.0020 - val_loss: 0.0083\n",
      "Epoch 134/600\n",
      "51/51 [==============================] - 0s 782us/step - loss: 0.0021 - val_loss: 0.0081\n",
      "Epoch 135/600\n",
      "51/51 [==============================] - 0s 792us/step - loss: 0.0020 - val_loss: 0.0085\n",
      "Epoch 136/600\n",
      "51/51 [==============================] - 0s 840us/step - loss: 0.0020 - val_loss: 0.0077\n",
      "Epoch 137/600\n",
      "51/51 [==============================] - 0s 958us/step - loss: 0.0020 - val_loss: 0.0082\n",
      "Epoch 138/600\n",
      "51/51 [==============================] - 0s 782us/step - loss: 0.0020 - val_loss: 0.0087\n",
      "Epoch 139/600\n",
      "51/51 [==============================] - 0s 821us/step - loss: 0.0021 - val_loss: 0.0084\n",
      "Epoch 140/600\n",
      "51/51 [==============================] - 0s 929us/step - loss: 0.0022 - val_loss: 0.0083\n",
      "Epoch 141/600\n",
      "51/51 [==============================] - 0s 879us/step - loss: 0.0021 - val_loss: 0.0081\n",
      "Epoch 142/600\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0080\n",
      "Epoch 143/600\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0083\n",
      "Epoch 144/600\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0082\n",
      "Epoch 145/600\n",
      "51/51 [==============================] - 0s 743us/step - loss: 0.0019 - val_loss: 0.0081\n",
      "Epoch 146/600\n",
      "51/51 [==============================] - 0s 754us/step - loss: 0.0020 - val_loss: 0.0085\n",
      "Epoch 147/600\n",
      "51/51 [==============================] - 0s 782us/step - loss: 0.0020 - val_loss: 0.0078\n",
      "Epoch 148/600\n",
      "51/51 [==============================] - 0s 875us/step - loss: 0.0019 - val_loss: 0.0082\n",
      "Epoch 149/600\n",
      "51/51 [==============================] - 0s 919us/step - loss: 0.0020 - val_loss: 0.0079\n",
      "Epoch 150/600\n",
      "51/51 [==============================] - 0s 772us/step - loss: 0.0020 - val_loss: 0.0083\n",
      "Epoch 151/600\n",
      "51/51 [==============================] - 0s 860us/step - loss: 0.0020 - val_loss: 0.0094\n",
      "Epoch 152/600\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0086\n",
      "Epoch 153/600\n",
      "51/51 [==============================] - 0s 899us/step - loss: 0.0020 - val_loss: 0.0082\n",
      "Epoch 154/600\n",
      "51/51 [==============================] - 0s 977us/step - loss: 0.0020 - val_loss: 0.0086\n",
      "Epoch 155/600\n",
      "51/51 [==============================] - 0s 918us/step - loss: 0.0019 - val_loss: 0.0078\n",
      "Epoch 156/600\n",
      "51/51 [==============================] - 0s 919us/step - loss: 0.0019 - val_loss: 0.0082\n",
      "Epoch 157/600\n",
      "51/51 [==============================] - 0s 762us/step - loss: 0.0020 - val_loss: 0.0081\n",
      "Epoch 158/600\n",
      "51/51 [==============================] - 0s 879us/step - loss: 0.0019 - val_loss: 0.0085\n",
      "Epoch 159/600\n",
      "51/51 [==============================] - 0s 860us/step - loss: 0.0019 - val_loss: 0.0082\n",
      "Epoch 160/600\n",
      "51/51 [==============================] - 0s 918us/step - loss: 0.0018 - val_loss: 0.0084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/600\n",
      "51/51 [==============================] - 0s 919us/step - loss: 0.0019 - val_loss: 0.0085\n",
      "Epoch 162/600\n",
      "51/51 [==============================] - 0s 898us/step - loss: 0.0018 - val_loss: 0.0078\n",
      "Epoch 163/600\n",
      "51/51 [==============================] - 0s 801us/step - loss: 0.0018 - val_loss: 0.0081\n",
      "Epoch 164/600\n",
      "51/51 [==============================] - 0s 801us/step - loss: 0.0019 - val_loss: 0.0084\n",
      "Epoch 165/600\n",
      "51/51 [==============================] - 0s 938us/step - loss: 0.0019 - val_loss: 0.0078\n",
      "Epoch 166/600\n",
      "51/51 [==============================] - 0s 860us/step - loss: 0.0024 - val_loss: 0.0087\n",
      "Epoch 167/600\n",
      "51/51 [==============================] - 0s 782us/step - loss: 0.0018 - val_loss: 0.0084\n",
      "Epoch 168/600\n",
      "51/51 [==============================] - 0s 743us/step - loss: 0.0018 - val_loss: 0.0081\n",
      "Epoch 169/600\n",
      "51/51 [==============================] - 0s 782us/step - loss: 0.0018 - val_loss: 0.0083\n",
      "Epoch 170/600\n",
      "51/51 [==============================] - 0s 801us/step - loss: 0.0018 - val_loss: 0.0077\n",
      "Epoch 171/600\n",
      "51/51 [==============================] - 0s 801us/step - loss: 0.0018 - val_loss: 0.0079\n",
      "Epoch 172/600\n",
      "51/51 [==============================] - 0s 938us/step - loss: 0.0018 - val_loss: 0.0082\n",
      "Epoch 173/600\n",
      "51/51 [==============================] - 0s 899us/step - loss: 0.0020 - val_loss: 0.0082\n",
      "Epoch 174/600\n",
      "51/51 [==============================] - 0s 977us/step - loss: 0.0019 - val_loss: 0.0078\n",
      "Epoch 175/600\n",
      "51/51 [==============================] - 0s 938us/step - loss: 0.0019 - val_loss: 0.0077\n",
      "Epoch 176/600\n",
      "51/51 [==============================] - 0s 911us/step - loss: 0.0018 - val_loss: 0.0082\n",
      "Epoch 177/600\n",
      "51/51 [==============================] - 0s 899us/step - loss: 0.0018 - val_loss: 0.0082\n",
      "Epoch 178/600\n",
      "51/51 [==============================] - 0s 782us/step - loss: 0.0017 - val_loss: 0.0084\n",
      "Epoch 179/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0017 - val_loss: 0.0079\n",
      "Epoch 180/600\n",
      "51/51 [==============================] - 0s 683us/step - loss: 0.0019 - val_loss: 0.0085\n",
      "Epoch 181/600\n",
      "51/51 [==============================] - 0s 704us/step - loss: 0.0017 - val_loss: 0.0082\n",
      "Epoch 182/600\n",
      "51/51 [==============================] - 0s 704us/step - loss: 0.0018 - val_loss: 0.0083\n",
      "Epoch 183/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0017 - val_loss: 0.0075\n",
      "Epoch 184/600\n",
      "51/51 [==============================] - 0s 678us/step - loss: 0.0018 - val_loss: 0.0079\n",
      "Epoch 185/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0018 - val_loss: 0.0082\n",
      "Epoch 186/600\n",
      "51/51 [==============================] - 0s 735us/step - loss: 0.0018 - val_loss: 0.0078\n",
      "Epoch 187/600\n",
      "51/51 [==============================] - 0s 703us/step - loss: 0.0017 - val_loss: 0.0085\n",
      "Epoch 188/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0018 - val_loss: 0.0082\n",
      "Epoch 189/600\n",
      "51/51 [==============================] - 0s 681us/step - loss: 0.0017 - val_loss: 0.0081\n",
      "Epoch 190/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0017 - val_loss: 0.0080\n",
      "Epoch 191/600\n",
      "51/51 [==============================] - 0s 704us/step - loss: 0.0018 - val_loss: 0.0082\n",
      "Epoch 192/600\n",
      "51/51 [==============================] - 0s 704us/step - loss: 0.0019 - val_loss: 0.0081\n",
      "Epoch 193/600\n",
      "51/51 [==============================] - 0s 703us/step - loss: 0.0019 - val_loss: 0.0082\n",
      "Epoch 194/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0017 - val_loss: 0.0079\n",
      "Epoch 195/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0018 - val_loss: 0.0086\n",
      "Epoch 196/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0017 - val_loss: 0.0083\n",
      "Epoch 197/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0019 - val_loss: 0.0081\n",
      "Epoch 198/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0017 - val_loss: 0.0079\n",
      "Epoch 199/600\n",
      "51/51 [==============================] - 0s 821us/step - loss: 0.0018 - val_loss: 0.0080\n",
      "Epoch 200/600\n",
      "51/51 [==============================] - 0s 840us/step - loss: 0.0017 - val_loss: 0.0079\n",
      "Epoch 201/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0018 - val_loss: 0.0083\n",
      "Epoch 202/600\n",
      "51/51 [==============================] - 0s 664us/step - loss: 0.0019 - val_loss: 0.0076\n",
      "Epoch 203/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0016 - val_loss: 0.0079\n",
      "Epoch 204/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0017 - val_loss: 0.0082\n",
      "Epoch 205/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0017 - val_loss: 0.0077\n",
      "Epoch 206/600\n",
      "51/51 [==============================] - 0s 743us/step - loss: 0.0016 - val_loss: 0.0076\n",
      "Epoch 207/600\n",
      "51/51 [==============================] - 0s 840us/step - loss: 0.0016 - val_loss: 0.0082\n",
      "Epoch 208/600\n",
      "51/51 [==============================] - 0s 703us/step - loss: 0.0017 - val_loss: 0.0079\n",
      "Epoch 209/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0016 - val_loss: 0.0082\n",
      "Epoch 210/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0017 - val_loss: 0.0078\n",
      "Epoch 211/600\n",
      "51/51 [==============================] - 0s 704us/step - loss: 0.0017 - val_loss: 0.0080\n",
      "Epoch 212/600\n",
      "51/51 [==============================] - 0s 762us/step - loss: 0.0017 - val_loss: 0.0079\n",
      "Epoch 213/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0017 - val_loss: 0.0075\n",
      "Epoch 214/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0016 - val_loss: 0.0079\n",
      "Epoch 215/600\n",
      "51/51 [==============================] - 0s 704us/step - loss: 0.0020 - val_loss: 0.0068\n",
      "Epoch 216/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0019 - val_loss: 0.0085\n",
      "Epoch 217/600\n",
      "51/51 [==============================] - 0s 703us/step - loss: 0.0016 - val_loss: 0.0083\n",
      "Epoch 218/600\n",
      "51/51 [==============================] - 0s 714us/step - loss: 0.0016 - val_loss: 0.0079\n",
      "Epoch 219/600\n",
      "51/51 [==============================] - 0s 704us/step - loss: 0.0018 - val_loss: 0.0080\n",
      "Epoch 220/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0018 - val_loss: 0.0082\n",
      "Epoch 221/600\n",
      "51/51 [==============================] - 0s 703us/step - loss: 0.0018 - val_loss: 0.0085\n",
      "Epoch 222/600\n",
      "51/51 [==============================] - 0s 664us/step - loss: 0.0017 - val_loss: 0.0075\n",
      "Epoch 223/600\n",
      "51/51 [==============================] - 0s 743us/step - loss: 0.0016 - val_loss: 0.0085\n",
      "Epoch 224/600\n",
      "51/51 [==============================] - 0s 696us/step - loss: 0.0017 - val_loss: 0.0084\n",
      "Epoch 225/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0016 - val_loss: 0.0079\n",
      "Epoch 226/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0017 - val_loss: 0.0081\n",
      "Epoch 227/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0016 - val_loss: 0.0079\n",
      "Epoch 228/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0016 - val_loss: 0.0078\n",
      "Epoch 229/600\n",
      "51/51 [==============================] - 0s 704us/step - loss: 0.0016 - val_loss: 0.0080\n",
      "Epoch 230/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0016 - val_loss: 0.0073\n",
      "Epoch 231/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0015 - val_loss: 0.0077\n",
      "Epoch 232/600\n",
      "51/51 [==============================] - 0s 700us/step - loss: 0.0016 - val_loss: 0.0081\n",
      "Epoch 233/600\n",
      "51/51 [==============================] - 0s 704us/step - loss: 0.0019 - val_loss: 0.0079\n",
      "Epoch 234/600\n",
      "51/51 [==============================] - 0s 704us/step - loss: 0.0016 - val_loss: 0.0082\n",
      "Epoch 235/600\n",
      "51/51 [==============================] - 0s 680us/step - loss: 0.0016 - val_loss: 0.0077\n",
      "Epoch 236/600\n",
      "51/51 [==============================] - 0s 703us/step - loss: 0.0016 - val_loss: 0.0078\n",
      "Epoch 237/600\n",
      "51/51 [==============================] - 0s 710us/step - loss: 0.0017 - val_loss: 0.0077\n",
      "Epoch 238/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0016 - val_loss: 0.0080\n",
      "Epoch 239/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0017 - val_loss: 0.0080\n",
      "Epoch 240/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 743us/step - loss: 0.0017 - val_loss: 0.0077\n",
      "Epoch 241/600\n",
      "51/51 [==============================] - 0s 664us/step - loss: 0.0016 - val_loss: 0.0082\n",
      "Epoch 242/600\n",
      "51/51 [==============================] - 0s 743us/step - loss: 0.0016 - val_loss: 0.0082\n",
      "Epoch 243/600\n",
      "51/51 [==============================] - 0s 841us/step - loss: 0.0017 - val_loss: 0.0080\n",
      "Epoch 244/600\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0086\n",
      "Epoch 245/600\n",
      "51/51 [==============================] - 0s 645us/step - loss: 0.0016 - val_loss: 0.0083\n",
      "Epoch 246/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0015 - val_loss: 0.0081\n",
      "Epoch 247/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0016 - val_loss: 0.0080\n",
      "Epoch 248/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0015 - val_loss: 0.0084\n",
      "Epoch 249/600\n",
      "51/51 [==============================] - 0s 664us/step - loss: 0.0015 - val_loss: 0.0080\n",
      "Epoch 250/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0015 - val_loss: 0.0080\n",
      "Epoch 251/600\n",
      "51/51 [==============================] - 0s 743us/step - loss: 0.0015 - val_loss: 0.0082\n",
      "Epoch 252/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0016 - val_loss: 0.0069\n",
      "Epoch 253/600\n",
      "51/51 [==============================] - 0s 704us/step - loss: 0.0017 - val_loss: 0.0077\n",
      "Epoch 254/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0015 - val_loss: 0.0076\n",
      "Epoch 255/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0016 - val_loss: 0.0074\n",
      "Epoch 256/600\n",
      "51/51 [==============================] - 0s 703us/step - loss: 0.0015 - val_loss: 0.0078\n",
      "Epoch 257/600\n",
      "51/51 [==============================] - 0s 703us/step - loss: 0.0015 - val_loss: 0.0076\n",
      "Epoch 258/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0015 - val_loss: 0.0077\n",
      "Epoch 259/600\n",
      "51/51 [==============================] - 0s 821us/step - loss: 0.0015 - val_loss: 0.0075\n",
      "Epoch 260/600\n",
      "51/51 [==============================] - 0s 997us/step - loss: 0.0015 - val_loss: 0.0081\n",
      "Epoch 261/600\n",
      "51/51 [==============================] - 0s 997us/step - loss: 0.0016 - val_loss: 0.0077\n",
      "Epoch 262/600\n",
      "51/51 [==============================] - 0s 782us/step - loss: 0.0015 - val_loss: 0.0081\n",
      "Epoch 263/600\n",
      "51/51 [==============================] - 0s 782us/step - loss: 0.0016 - val_loss: 0.0079\n",
      "Epoch 264/600\n",
      "51/51 [==============================] - 0s 704us/step - loss: 0.0015 - val_loss: 0.0083\n",
      "Epoch 265/600\n",
      "51/51 [==============================] - 0s 743us/step - loss: 0.0016 - val_loss: 0.0080\n",
      "Epoch 266/600\n",
      "51/51 [==============================] - 0s 703us/step - loss: 0.0015 - val_loss: 0.0078\n",
      "Epoch 267/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0015 - val_loss: 0.0081\n",
      "Epoch 268/600\n",
      "51/51 [==============================] - 0s 738us/step - loss: 0.0015 - val_loss: 0.0079\n",
      "Epoch 269/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0015 - val_loss: 0.0079\n",
      "Epoch 270/600\n",
      "51/51 [==============================] - 0s 762us/step - loss: 0.0015 - val_loss: 0.0077\n",
      "Epoch 271/600\n",
      "51/51 [==============================] - 0s 645us/step - loss: 0.0015 - val_loss: 0.0080\n",
      "Epoch 272/600\n",
      "51/51 [==============================] - 0s 704us/step - loss: 0.0015 - val_loss: 0.0079\n",
      "Epoch 273/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0016 - val_loss: 0.0077\n",
      "Epoch 274/600\n",
      "51/51 [==============================] - 0s 762us/step - loss: 0.0015 - val_loss: 0.0082\n",
      "Epoch 275/600\n",
      "51/51 [==============================] - 0s 695us/step - loss: 0.0016 - val_loss: 0.0083\n",
      "Epoch 276/600\n",
      "51/51 [==============================] - 0s 704us/step - loss: 0.0015 - val_loss: 0.0074\n",
      "Epoch 277/600\n",
      "51/51 [==============================] - 0s 782us/step - loss: 0.0015 - val_loss: 0.0075\n",
      "Epoch 278/600\n",
      "51/51 [==============================] - 0s 694us/step - loss: 0.0014 - val_loss: 0.0081\n",
      "Epoch 279/600\n",
      "51/51 [==============================] - 0s 703us/step - loss: 0.0015 - val_loss: 0.0078\n",
      "Epoch 280/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0014 - val_loss: 0.0080\n",
      "Epoch 281/600\n",
      "51/51 [==============================] - 0s 734us/step - loss: 0.0015 - val_loss: 0.0085\n",
      "Epoch 282/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0015 - val_loss: 0.0079\n",
      "Epoch 283/600\n",
      "51/51 [==============================] - 0s 695us/step - loss: 0.0016 - val_loss: 0.0075\n",
      "Epoch 284/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0015 - val_loss: 0.0076\n",
      "Epoch 285/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0016 - val_loss: 0.0076\n",
      "Epoch 286/600\n",
      "51/51 [==============================] - 0s 703us/step - loss: 0.0015 - val_loss: 0.0078\n",
      "Epoch 287/600\n",
      "51/51 [==============================] - 0s 704us/step - loss: 0.0015 - val_loss: 0.0081\n",
      "Epoch 288/600\n",
      "51/51 [==============================] - 0s 704us/step - loss: 0.0014 - val_loss: 0.0079\n",
      "Epoch 289/600\n",
      "51/51 [==============================] - 0s 801us/step - loss: 0.0014 - val_loss: 0.0079\n",
      "Epoch 290/600\n",
      "51/51 [==============================] - 0s 879us/step - loss: 0.0016 - val_loss: 0.0078\n",
      "Epoch 291/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0015 - val_loss: 0.0077\n",
      "Epoch 292/600\n",
      "51/51 [==============================] - 0s 704us/step - loss: 0.0015 - val_loss: 0.0082\n",
      "Epoch 293/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0015 - val_loss: 0.0078\n",
      "Epoch 294/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0015 - val_loss: 0.0080\n",
      "Epoch 295/600\n",
      "51/51 [==============================] - 0s 919us/step - loss: 0.0014 - val_loss: 0.0081\n",
      "Epoch 296/600\n",
      "51/51 [==============================] - 0s 782us/step - loss: 0.0016 - val_loss: 0.0080\n",
      "Epoch 297/600\n",
      "51/51 [==============================] - 0s 703us/step - loss: 0.0016 - val_loss: 0.0079\n",
      "Epoch 298/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0014 - val_loss: 0.0077\n",
      "Epoch 299/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0015 - val_loss: 0.0081\n",
      "Epoch 300/600\n",
      "51/51 [==============================] - 0s 704us/step - loss: 0.0017 - val_loss: 0.0068\n",
      "Epoch 301/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0015 - val_loss: 0.0073\n",
      "Epoch 302/600\n",
      "51/51 [==============================] - 0s 703us/step - loss: 0.0014 - val_loss: 0.0073\n",
      "Epoch 303/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0016 - val_loss: 0.0072\n",
      "Epoch 304/600\n",
      "51/51 [==============================] - 0s 704us/step - loss: 0.0013 - val_loss: 0.0079\n",
      "Epoch 305/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0016 - val_loss: 0.0077\n",
      "Epoch 306/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0014 - val_loss: 0.0077\n",
      "Epoch 307/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0016 - val_loss: 0.0078\n",
      "Epoch 308/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0014 - val_loss: 0.0079\n",
      "Epoch 309/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0015 - val_loss: 0.0072\n",
      "Epoch 310/600\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0073\n",
      "Epoch 311/600\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0078\n",
      "Epoch 312/600\n",
      "51/51 [==============================] - 0s 840us/step - loss: 0.0014 - val_loss: 0.0073\n",
      "Epoch 313/600\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0075\n",
      "Epoch 314/600\n",
      "51/51 [==============================] - 0s 840us/step - loss: 0.0014 - val_loss: 0.0077\n",
      "Epoch 315/600\n",
      "51/51 [==============================] - 0s 821us/step - loss: 0.0014 - val_loss: 0.0075\n",
      "Epoch 316/600\n",
      "51/51 [==============================] - 0s 795us/step - loss: 0.0015 - val_loss: 0.0075\n",
      "Epoch 317/600\n",
      "51/51 [==============================] - 0s 743us/step - loss: 0.0016 - val_loss: 0.0075\n",
      "Epoch 318/600\n",
      "51/51 [==============================] - 0s 717us/step - loss: 0.0014 - val_loss: 0.0074\n",
      "Epoch 319/600\n",
      "51/51 [==============================] - 0s 704us/step - loss: 0.0014 - val_loss: 0.0073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 320/600\n",
      "51/51 [==============================] - 0s 743us/step - loss: 0.0014 - val_loss: 0.0081\n",
      "Epoch 321/600\n",
      "51/51 [==============================] - 0s 703us/step - loss: 0.0014 - val_loss: 0.0076\n",
      "Epoch 322/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0013 - val_loss: 0.0076\n",
      "Epoch 323/600\n",
      "51/51 [==============================] - 0s 742us/step - loss: 0.0013 - val_loss: 0.0073\n",
      "Epoch 324/600\n",
      "51/51 [==============================] - 0s 703us/step - loss: 0.0015 - val_loss: 0.0079\n",
      "Epoch 325/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0014 - val_loss: 0.0077\n",
      "Epoch 326/600\n",
      "51/51 [==============================] - 0s 717us/step - loss: 0.0014 - val_loss: 0.0072\n",
      "Epoch 327/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0014 - val_loss: 0.0077\n",
      "Epoch 328/600\n",
      "51/51 [==============================] - 0s 704us/step - loss: 0.0014 - val_loss: 0.0076\n",
      "Epoch 329/600\n",
      "51/51 [==============================] - 0s 694us/step - loss: 0.0014 - val_loss: 0.0075\n",
      "Epoch 330/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0014 - val_loss: 0.0074\n",
      "Epoch 331/600\n",
      "51/51 [==============================] - 0s 709us/step - loss: 0.0014 - val_loss: 0.0077\n",
      "Epoch 332/600\n",
      "51/51 [==============================] - 0s 743us/step - loss: 0.0014 - val_loss: 0.0078\n",
      "Epoch 333/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0014 - val_loss: 0.0070\n",
      "Epoch 334/600\n",
      "51/51 [==============================] - 0s 743us/step - loss: 0.0016 - val_loss: 0.0073\n",
      "Epoch 335/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0014 - val_loss: 0.0073\n",
      "Epoch 336/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0014 - val_loss: 0.0073\n",
      "Epoch 337/600\n",
      "51/51 [==============================] - 0s 782us/step - loss: 0.0014 - val_loss: 0.0074\n",
      "Epoch 338/600\n",
      "51/51 [==============================] - 0s 762us/step - loss: 0.0014 - val_loss: 0.0067\n",
      "Epoch 339/600\n",
      "51/51 [==============================] - 0s 762us/step - loss: 0.0014 - val_loss: 0.0073\n",
      "Epoch 340/600\n",
      "51/51 [==============================] - 0s 762us/step - loss: 0.0014 - val_loss: 0.0075\n",
      "Epoch 341/600\n",
      "51/51 [==============================] - 0s 742us/step - loss: 0.0015 - val_loss: 0.0069\n",
      "Epoch 342/600\n",
      "51/51 [==============================] - 0s 782us/step - loss: 0.0014 - val_loss: 0.0072\n",
      "Epoch 343/600\n",
      "51/51 [==============================] - 0s 782us/step - loss: 0.0013 - val_loss: 0.0075\n",
      "Epoch 344/600\n",
      "51/51 [==============================] - 0s 821us/step - loss: 0.0014 - val_loss: 0.0072\n",
      "Epoch 345/600\n",
      "51/51 [==============================] - 0s 918us/step - loss: 0.0014 - val_loss: 0.0073\n",
      "Epoch 346/600\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0074\n",
      "Epoch 347/600\n",
      "51/51 [==============================] - 0s 919us/step - loss: 0.0015 - val_loss: 0.0074\n",
      "Epoch 348/600\n",
      "51/51 [==============================] - 0s 997us/step - loss: 0.0014 - val_loss: 0.0076\n",
      "Epoch 349/600\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0078\n",
      "Epoch 350/600\n",
      "51/51 [==============================] - 0s 957us/step - loss: 0.0016 - val_loss: 0.0078\n",
      "Epoch 351/600\n",
      "51/51 [==============================] - 0s 977us/step - loss: 0.0015 - val_loss: 0.0074\n",
      "Epoch 352/600\n",
      "51/51 [==============================] - 0s 840us/step - loss: 0.0013 - val_loss: 0.0072\n",
      "Epoch 353/600\n",
      "51/51 [==============================] - 0s 918us/step - loss: 0.0013 - val_loss: 0.0074\n",
      "Epoch 354/600\n",
      "51/51 [==============================] - 0s 821us/step - loss: 0.0013 - val_loss: 0.0074\n",
      "Epoch 355/600\n",
      "51/51 [==============================] - 0s 879us/step - loss: 0.0013 - val_loss: 0.0074\n",
      "Epoch 356/600\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0076\n",
      "Epoch 357/600\n",
      "51/51 [==============================] - 0s 918us/step - loss: 0.0013 - val_loss: 0.0077\n",
      "Epoch 358/600\n",
      "51/51 [==============================] - 0s 938us/step - loss: 0.0013 - val_loss: 0.0071\n",
      "Epoch 359/600\n",
      "51/51 [==============================] - 0s 860us/step - loss: 0.0013 - val_loss: 0.0078\n",
      "Epoch 360/600\n",
      "51/51 [==============================] - 0s 997us/step - loss: 0.0014 - val_loss: 0.0073\n",
      "Epoch 361/600\n",
      "51/51 [==============================] - 0s 977us/step - loss: 0.0013 - val_loss: 0.0072\n",
      "Epoch 362/600\n",
      "51/51 [==============================] - 0s 840us/step - loss: 0.0013 - val_loss: 0.0073\n",
      "Epoch 363/600\n",
      "51/51 [==============================] - 0s 801us/step - loss: 0.0013 - val_loss: 0.0073\n",
      "Epoch 364/600\n",
      "51/51 [==============================] - 0s 812us/step - loss: 0.0013 - val_loss: 0.0071\n",
      "Epoch 365/600\n",
      "51/51 [==============================] - 0s 899us/step - loss: 0.0014 - val_loss: 0.0074\n",
      "Epoch 366/600\n",
      "51/51 [==============================] - 0s 938us/step - loss: 0.0015 - val_loss: 0.0070\n",
      "Epoch 367/600\n",
      "51/51 [==============================] - 0s 872us/step - loss: 0.0013 - val_loss: 0.0072\n",
      "Epoch 368/600\n",
      "51/51 [==============================] - 0s 841us/step - loss: 0.0013 - val_loss: 0.0076\n",
      "Epoch 369/600\n",
      "51/51 [==============================] - 0s 851us/step - loss: 0.0013 - val_loss: 0.0074\n",
      "Epoch 370/600\n",
      "51/51 [==============================] - 0s 860us/step - loss: 0.0013 - val_loss: 0.0070\n",
      "Epoch 371/600\n",
      "51/51 [==============================] - 0s 821us/step - loss: 0.0013 - val_loss: 0.0074\n",
      "Epoch 372/600\n",
      "51/51 [==============================] - 0s 898us/step - loss: 0.0013 - val_loss: 0.0071\n",
      "Epoch 373/600\n",
      "51/51 [==============================] - 0s 821us/step - loss: 0.0013 - val_loss: 0.0073\n",
      "Epoch 374/600\n",
      "51/51 [==============================] - 0s 840us/step - loss: 0.0013 - val_loss: 0.0071\n",
      "Epoch 375/600\n",
      "51/51 [==============================] - 0s 781us/step - loss: 0.0013 - val_loss: 0.0074\n",
      "Epoch 376/600\n",
      "51/51 [==============================] - 0s 782us/step - loss: 0.0013 - val_loss: 0.0074\n",
      "Epoch 377/600\n",
      "51/51 [==============================] - 0s 782us/step - loss: 0.0014 - val_loss: 0.0067\n",
      "Epoch 378/600\n",
      "51/51 [==============================] - 0s 860us/step - loss: 0.0013 - val_loss: 0.0077\n",
      "Epoch 379/600\n",
      "51/51 [==============================] - 0s 996us/step - loss: 0.0014 - val_loss: 0.0072\n",
      "Epoch 380/600\n",
      "51/51 [==============================] - 0s 938us/step - loss: 0.0014 - val_loss: 0.0074\n",
      "Epoch 381/600\n",
      "51/51 [==============================] - 0s 840us/step - loss: 0.0013 - val_loss: 0.0074\n",
      "Epoch 382/600\n",
      "51/51 [==============================] - 0s 821us/step - loss: 0.0013 - val_loss: 0.0074\n",
      "Epoch 383/600\n",
      "51/51 [==============================] - 0s 918us/step - loss: 0.0014 - val_loss: 0.0074\n",
      "Epoch 384/600\n",
      "51/51 [==============================] - 0s 918us/step - loss: 0.0014 - val_loss: 0.0070\n",
      "Epoch 385/600\n",
      "51/51 [==============================] - 0s 879us/step - loss: 0.0013 - val_loss: 0.0070\n",
      "Epoch 386/600\n",
      "51/51 [==============================] - 0s 899us/step - loss: 0.0014 - val_loss: 0.0069\n",
      "Epoch 387/600\n",
      "51/51 [==============================] - 0s 782us/step - loss: 0.0013 - val_loss: 0.0070\n",
      "Epoch 388/600\n",
      "51/51 [==============================] - 0s 840us/step - loss: 0.0013 - val_loss: 0.0069\n",
      "Epoch 389/600\n",
      "51/51 [==============================] - 0s 821us/step - loss: 0.0013 - val_loss: 0.0079\n",
      "Epoch 390/600\n",
      "51/51 [==============================] - 0s 801us/step - loss: 0.0014 - val_loss: 0.0073\n",
      "Epoch 391/600\n",
      "51/51 [==============================] - 0s 899us/step - loss: 0.0013 - val_loss: 0.0074\n",
      "Epoch 392/600\n",
      "51/51 [==============================] - 0s 919us/step - loss: 0.0013 - val_loss: 0.0069\n",
      "Epoch 393/600\n",
      "51/51 [==============================] - 0s 997us/step - loss: 0.0013 - val_loss: 0.0070\n",
      "Epoch 394/600\n",
      "51/51 [==============================] - 0s 958us/step - loss: 0.0013 - val_loss: 0.0074\n",
      "Epoch 395/600\n",
      "51/51 [==============================] - 0s 945us/step - loss: 0.0013 - val_loss: 0.0072\n",
      "Epoch 396/600\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0074\n",
      "Epoch 397/600\n",
      "51/51 [==============================] - 0s 842us/step - loss: 0.0013 - val_loss: 0.0072\n",
      "Epoch 398/600\n",
      "51/51 [==============================] - 0s 879us/step - loss: 0.0013 - val_loss: 0.0071\n",
      "Epoch 399/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 860us/step - loss: 0.0013 - val_loss: 0.0072\n",
      "Epoch 400/600\n",
      "51/51 [==============================] - 0s 821us/step - loss: 0.0013 - val_loss: 0.0071\n",
      "Epoch 401/600\n",
      "51/51 [==============================] - 0s 879us/step - loss: 0.0013 - val_loss: 0.0072\n",
      "Epoch 402/600\n",
      "51/51 [==============================] - 0s 703us/step - loss: 0.0014 - val_loss: 0.0077\n",
      "Epoch 403/600\n",
      "51/51 [==============================] - 0s 703us/step - loss: 0.0013 - val_loss: 0.0074\n",
      "Epoch 404/600\n",
      "51/51 [==============================] - 0s 736us/step - loss: 0.0013 - val_loss: 0.0071\n",
      "Epoch 405/600\n",
      "51/51 [==============================] - 0s 742us/step - loss: 0.0013 - val_loss: 0.0070\n",
      "Epoch 406/600\n",
      "51/51 [==============================] - 0s 703us/step - loss: 0.0014 - val_loss: 0.0069\n",
      "Epoch 407/600\n",
      "51/51 [==============================] - 0s 754us/step - loss: 0.0013 - val_loss: 0.0073\n",
      "Epoch 408/600\n",
      "51/51 [==============================] - 0s 704us/step - loss: 0.0013 - val_loss: 0.0071\n",
      "Epoch 409/600\n",
      "51/51 [==============================] - 0s 694us/step - loss: 0.0012 - val_loss: 0.0075\n",
      "Epoch 410/600\n",
      "51/51 [==============================] - 0s 704us/step - loss: 0.0014 - val_loss: 0.0068\n",
      "Epoch 411/600\n",
      "51/51 [==============================] - 0s 762us/step - loss: 0.0015 - val_loss: 0.0071\n",
      "Epoch 412/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0012 - val_loss: 0.0071\n",
      "Epoch 413/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0013 - val_loss: 0.0066\n",
      "Epoch 414/600\n",
      "51/51 [==============================] - 0s 743us/step - loss: 0.0015 - val_loss: 0.0076\n",
      "Epoch 415/600\n",
      "51/51 [==============================] - 0s 743us/step - loss: 0.0014 - val_loss: 0.0071\n",
      "Epoch 416/600\n",
      "51/51 [==============================] - 0s 703us/step - loss: 0.0013 - val_loss: 0.0068\n",
      "Epoch 417/600\n",
      "51/51 [==============================] - 0s 762us/step - loss: 0.0012 - val_loss: 0.0070\n",
      "Epoch 418/600\n",
      "51/51 [==============================] - 0s 997us/step - loss: 0.0012 - val_loss: 0.0072\n",
      "Epoch 419/600\n",
      "51/51 [==============================] - 0s 743us/step - loss: 0.0014 - val_loss: 0.0082\n",
      "Epoch 420/600\n",
      "51/51 [==============================] - 0s 742us/step - loss: 0.0013 - val_loss: 0.0074\n",
      "Epoch 421/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0013 - val_loss: 0.0072\n",
      "Epoch 422/600\n",
      "51/51 [==============================] - 0s 703us/step - loss: 0.0013 - val_loss: 0.0069\n",
      "Epoch 423/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0013 - val_loss: 0.0072\n",
      "Epoch 424/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0012 - val_loss: 0.0068\n",
      "Epoch 425/600\n",
      "51/51 [==============================] - 0s 704us/step - loss: 0.0013 - val_loss: 0.0073\n",
      "Epoch 426/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0013 - val_loss: 0.0070\n",
      "Epoch 427/600\n",
      "51/51 [==============================] - 0s 703us/step - loss: 0.0013 - val_loss: 0.0073\n",
      "Epoch 428/600\n",
      "51/51 [==============================] - 0s 704us/step - loss: 0.0014 - val_loss: 0.0075\n",
      "Epoch 429/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0014 - val_loss: 0.0087\n",
      "Epoch 430/600\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.0014 - val_loss: 0.0071\n",
      "Epoch 431/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0013 - val_loss: 0.0071\n",
      "Epoch 432/600\n",
      "51/51 [==============================] - 0s 743us/step - loss: 0.0012 - val_loss: 0.0075\n",
      "Epoch 433/600\n",
      "51/51 [==============================] - 0s 743us/step - loss: 0.0013 - val_loss: 0.0072\n",
      "Epoch 434/600\n",
      "51/51 [==============================] - 0s 743us/step - loss: 0.0012 - val_loss: 0.0072\n",
      "Epoch 435/600\n",
      "51/51 [==============================] - 0s 704us/step - loss: 0.0013 - val_loss: 0.0069\n",
      "Epoch 436/600\n",
      "51/51 [==============================] - 0s 704us/step - loss: 0.0012 - val_loss: 0.0075\n",
      "Epoch 437/600\n",
      "51/51 [==============================] - 0s 704us/step - loss: 0.0013 - val_loss: 0.0073\n",
      "Epoch 438/600\n",
      "51/51 [==============================] - 0s 742us/step - loss: 0.0013 - val_loss: 0.0067\n",
      "Epoch 439/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0012 - val_loss: 0.0066\n",
      "Epoch 440/600\n",
      "51/51 [==============================] - 0s 743us/step - loss: 0.0013 - val_loss: 0.0077\n",
      "Epoch 441/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0013 - val_loss: 0.0074\n",
      "Epoch 442/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0013 - val_loss: 0.0071\n",
      "Epoch 443/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0013 - val_loss: 0.0075\n",
      "Epoch 444/600\n",
      "51/51 [==============================] - 0s 704us/step - loss: 0.0013 - val_loss: 0.0069\n",
      "Epoch 445/600\n",
      "51/51 [==============================] - 0s 743us/step - loss: 0.0013 - val_loss: 0.0074\n",
      "Epoch 446/600\n",
      "51/51 [==============================] - 0s 704us/step - loss: 0.0012 - val_loss: 0.0070\n",
      "Epoch 447/600\n",
      "51/51 [==============================] - 0s 704us/step - loss: 0.0013 - val_loss: 0.0070\n",
      "Epoch 448/600\n",
      "51/51 [==============================] - 0s 743us/step - loss: 0.0014 - val_loss: 0.0070\n",
      "Epoch 449/600\n",
      "51/51 [==============================] - 0s 762us/step - loss: 0.0015 - val_loss: 0.0073\n",
      "Epoch 450/600\n",
      "51/51 [==============================] - 0s 918us/step - loss: 0.0013 - val_loss: 0.0072\n",
      "Epoch 451/600\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0071\n",
      "Epoch 452/600\n",
      "51/51 [==============================] - 0s 938us/step - loss: 0.0012 - val_loss: 0.0074\n",
      "Epoch 453/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0012 - val_loss: 0.0066\n",
      "Epoch 454/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0014 - val_loss: 0.0068\n",
      "Epoch 455/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0013 - val_loss: 0.0073\n",
      "Epoch 456/600\n",
      "51/51 [==============================] - 0s 742us/step - loss: 0.0013 - val_loss: 0.0070\n",
      "Epoch 457/600\n",
      "51/51 [==============================] - 0s 703us/step - loss: 0.0012 - val_loss: 0.0069\n",
      "Epoch 458/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0013 - val_loss: 0.0070\n",
      "Epoch 459/600\n",
      "51/51 [==============================] - 0s 704us/step - loss: 0.0014 - val_loss: 0.0071\n",
      "Epoch 460/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0012 - val_loss: 0.0076\n",
      "Epoch 461/600\n",
      "51/51 [==============================] - 0s 743us/step - loss: 0.0013 - val_loss: 0.0077\n",
      "Epoch 462/600\n",
      "51/51 [==============================] - 0s 704us/step - loss: 0.0013 - val_loss: 0.0071\n",
      "Epoch 463/600\n",
      "51/51 [==============================] - 0s 704us/step - loss: 0.0013 - val_loss: 0.0074\n",
      "Epoch 464/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0013 - val_loss: 0.0072\n",
      "Epoch 465/600\n",
      "51/51 [==============================] - 0s 762us/step - loss: 0.0012 - val_loss: 0.0073\n",
      "Epoch 466/600\n",
      "51/51 [==============================] - 0s 743us/step - loss: 0.0013 - val_loss: 0.0073\n",
      "Epoch 467/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0012 - val_loss: 0.0075\n",
      "Epoch 468/600\n",
      "51/51 [==============================] - 0s 782us/step - loss: 0.0012 - val_loss: 0.0073\n",
      "Epoch 469/600\n",
      "51/51 [==============================] - 0s 743us/step - loss: 0.0012 - val_loss: 0.0070\n",
      "Epoch 470/600\n",
      "51/51 [==============================] - 0s 743us/step - loss: 0.0012 - val_loss: 0.0070\n",
      "Epoch 471/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0012 - val_loss: 0.0073\n",
      "Epoch 472/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0012 - val_loss: 0.0072\n",
      "Epoch 473/600\n",
      "51/51 [==============================] - 0s 703us/step - loss: 0.0013 - val_loss: 0.0071\n",
      "Epoch 474/600\n",
      "51/51 [==============================] - 0s 743us/step - loss: 0.0013 - val_loss: 0.0070\n",
      "Epoch 475/600\n",
      "51/51 [==============================] - 0s 704us/step - loss: 0.0013 - val_loss: 0.0065\n",
      "Epoch 476/600\n",
      "51/51 [==============================] - 0s 821us/step - loss: 0.0012 - val_loss: 0.0070\n",
      "Epoch 477/600\n",
      "51/51 [==============================] - 0s 743us/step - loss: 0.0012 - val_loss: 0.0068\n",
      "Epoch 478/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 795us/step - loss: 0.0012 - val_loss: 0.0073\n",
      "Epoch 479/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0012 - val_loss: 0.0073\n",
      "Epoch 480/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0012 - val_loss: 0.0067\n",
      "Epoch 481/600\n",
      "51/51 [==============================] - 0s 734us/step - loss: 0.0013 - val_loss: 0.0075\n",
      "Epoch 482/600\n",
      "51/51 [==============================] - 0s 879us/step - loss: 0.0013 - val_loss: 0.0067\n",
      "Epoch 483/600\n",
      "51/51 [==============================] - 0s 832us/step - loss: 0.0012 - val_loss: 0.0071\n",
      "Epoch 484/600\n",
      "51/51 [==============================] - 0s 821us/step - loss: 0.0012 - val_loss: 0.0073\n",
      "Epoch 485/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0013 - val_loss: 0.0077\n",
      "Epoch 486/600\n",
      "51/51 [==============================] - 0s 821us/step - loss: 0.0013 - val_loss: 0.0074\n",
      "Epoch 487/600\n",
      "51/51 [==============================] - 0s 801us/step - loss: 0.0012 - val_loss: 0.0072\n",
      "Epoch 488/600\n",
      "51/51 [==============================] - 0s 821us/step - loss: 0.0012 - val_loss: 0.0070\n",
      "Epoch 489/600\n",
      "51/51 [==============================] - 0s 782us/step - loss: 0.0012 - val_loss: 0.0072\n",
      "Epoch 490/600\n",
      "51/51 [==============================] - 0s 813us/step - loss: 0.0014 - val_loss: 0.0072\n",
      "Epoch 491/600\n",
      "51/51 [==============================] - 0s 743us/step - loss: 0.0014 - val_loss: 0.0075\n",
      "Epoch 492/600\n",
      "51/51 [==============================] - 0s 782us/step - loss: 0.0013 - val_loss: 0.0071\n",
      "Epoch 493/600\n",
      "51/51 [==============================] - 0s 755us/step - loss: 0.0012 - val_loss: 0.0071\n",
      "Epoch 494/600\n",
      "51/51 [==============================] - 0s 860us/step - loss: 0.0013 - val_loss: 0.0073\n",
      "Epoch 495/600\n",
      "51/51 [==============================] - 0s 781us/step - loss: 0.0012 - val_loss: 0.0077\n",
      "Epoch 496/600\n",
      "51/51 [==============================] - 0s 840us/step - loss: 0.0013 - val_loss: 0.0068\n",
      "Epoch 497/600\n",
      "51/51 [==============================] - 0s 801us/step - loss: 0.0014 - val_loss: 0.0075\n",
      "Epoch 498/600\n",
      "51/51 [==============================] - 0s 801us/step - loss: 0.0012 - val_loss: 0.0069\n",
      "Epoch 499/600\n",
      "51/51 [==============================] - 0s 899us/step - loss: 0.0012 - val_loss: 0.0074\n",
      "Epoch 500/600\n",
      "51/51 [==============================] - 0s 977us/step - loss: 0.0012 - val_loss: 0.0069\n",
      "Epoch 501/600\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0073\n",
      "Epoch 502/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0015 - val_loss: 0.0077\n",
      "Epoch 503/600\n",
      "51/51 [==============================] - 0s 860us/step - loss: 0.0014 - val_loss: 0.0081\n",
      "Epoch 504/600\n",
      "51/51 [==============================] - 0s 879us/step - loss: 0.0013 - val_loss: 0.0071\n",
      "Epoch 505/600\n",
      "51/51 [==============================] - 0s 840us/step - loss: 0.0012 - val_loss: 0.0070\n",
      "Epoch 506/600\n",
      "51/51 [==============================] - 0s 879us/step - loss: 0.0011 - val_loss: 0.0070\n",
      "Epoch 507/600\n",
      "51/51 [==============================] - 0s 938us/step - loss: 0.0012 - val_loss: 0.0070\n",
      "Epoch 508/600\n",
      "51/51 [==============================] - 0s 840us/step - loss: 0.0012 - val_loss: 0.0072\n",
      "Epoch 509/600\n",
      "51/51 [==============================] - 0s 801us/step - loss: 0.0011 - val_loss: 0.0069\n",
      "Epoch 510/600\n",
      "51/51 [==============================] - 0s 938us/step - loss: 0.0012 - val_loss: 0.0071\n",
      "Epoch 511/600\n",
      "51/51 [==============================] - 0s 958us/step - loss: 0.0012 - val_loss: 0.0072\n",
      "Epoch 512/600\n",
      "51/51 [==============================] - 0s 919us/step - loss: 0.0012 - val_loss: 0.0068\n",
      "Epoch 513/600\n",
      "51/51 [==============================] - 0s 899us/step - loss: 0.0011 - val_loss: 0.0073\n",
      "Epoch 514/600\n",
      "51/51 [==============================] - 0s 997us/step - loss: 0.0012 - val_loss: 0.0073\n",
      "Epoch 515/600\n",
      "51/51 [==============================] - 0s 938us/step - loss: 0.0012 - val_loss: 0.0075\n",
      "Epoch 516/600\n",
      "51/51 [==============================] - 0s 977us/step - loss: 0.0012 - val_loss: 0.0070\n",
      "Epoch 517/600\n",
      "51/51 [==============================] - 0s 938us/step - loss: 0.0012 - val_loss: 0.0072\n",
      "Epoch 518/600\n",
      "51/51 [==============================] - 0s 896us/step - loss: 0.0012 - val_loss: 0.0069\n",
      "Epoch 519/600\n",
      "51/51 [==============================] - 0s 879us/step - loss: 0.0012 - val_loss: 0.0071\n",
      "Epoch 520/600\n",
      "51/51 [==============================] - 0s 879us/step - loss: 0.0012 - val_loss: 0.0079\n",
      "Epoch 521/600\n",
      "51/51 [==============================] - 0s 938us/step - loss: 0.0011 - val_loss: 0.0076\n",
      "Epoch 522/600\n",
      "51/51 [==============================] - 0s 938us/step - loss: 0.0011 - val_loss: 0.0071\n",
      "Epoch 523/600\n",
      "51/51 [==============================] - 0s 997us/step - loss: 0.0011 - val_loss: 0.0070\n",
      "Epoch 524/600\n",
      "51/51 [==============================] - 0s 997us/step - loss: 0.0013 - val_loss: 0.0069\n",
      "Epoch 525/600\n",
      "51/51 [==============================] - 0s 938us/step - loss: 0.0014 - val_loss: 0.0073\n",
      "Epoch 526/600\n",
      "51/51 [==============================] - 0s 915us/step - loss: 0.0011 - val_loss: 0.0069\n",
      "Epoch 527/600\n",
      "51/51 [==============================] - 0s 879us/step - loss: 0.0012 - val_loss: 0.0069\n",
      "Epoch 528/600\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0071\n",
      "Epoch 529/600\n",
      "51/51 [==============================] - 0s 938us/step - loss: 0.0013 - val_loss: 0.0069\n",
      "Epoch 530/600\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0070\n",
      "Epoch 531/600\n",
      "51/51 [==============================] - 0s 840us/step - loss: 0.0013 - val_loss: 0.0068\n",
      "Epoch 532/600\n",
      "51/51 [==============================] - 0s 977us/step - loss: 0.0013 - val_loss: 0.0067\n",
      "Epoch 533/600\n",
      "51/51 [==============================] - 0s 938us/step - loss: 0.0012 - val_loss: 0.0069\n",
      "Epoch 534/600\n",
      "51/51 [==============================] - 0s 901us/step - loss: 0.0012 - val_loss: 0.0067\n",
      "Epoch 535/600\n",
      "51/51 [==============================] - 0s 899us/step - loss: 0.0012 - val_loss: 0.0071\n",
      "Epoch 536/600\n",
      "51/51 [==============================] - 0s 801us/step - loss: 0.0012 - val_loss: 0.0079\n",
      "Epoch 537/600\n",
      "51/51 [==============================] - 0s 801us/step - loss: 0.0015 - val_loss: 0.0076\n",
      "Epoch 538/600\n",
      "51/51 [==============================] - 0s 743us/step - loss: 0.0013 - val_loss: 0.0072\n",
      "Epoch 539/600\n",
      "51/51 [==============================] - 0s 860us/step - loss: 0.0011 - val_loss: 0.0067\n",
      "Epoch 540/600\n",
      "51/51 [==============================] - 0s 899us/step - loss: 0.0012 - val_loss: 0.0070\n",
      "Epoch 541/600\n",
      "51/51 [==============================] - 0s 880us/step - loss: 0.0012 - val_loss: 0.0073\n",
      "Epoch 542/600\n",
      "51/51 [==============================] - 0s 879us/step - loss: 0.0011 - val_loss: 0.0073\n",
      "Epoch 543/600\n",
      "51/51 [==============================] - 0s 821us/step - loss: 0.0012 - val_loss: 0.0074\n",
      "Epoch 544/600\n",
      "51/51 [==============================] - 0s 762us/step - loss: 0.0012 - val_loss: 0.0070\n",
      "Epoch 545/600\n",
      "51/51 [==============================] - 0s 821us/step - loss: 0.0011 - val_loss: 0.0074\n",
      "Epoch 546/600\n",
      "51/51 [==============================] - 0s 821us/step - loss: 0.0011 - val_loss: 0.0077\n",
      "Epoch 547/600\n",
      "51/51 [==============================] - 0s 821us/step - loss: 0.0012 - val_loss: 0.0075\n",
      "Epoch 548/600\n",
      "51/51 [==============================] - 0s 840us/step - loss: 0.0012 - val_loss: 0.0068\n",
      "Epoch 549/600\n",
      "51/51 [==============================] - 0s 840us/step - loss: 0.0012 - val_loss: 0.0067\n",
      "Epoch 550/600\n",
      "51/51 [==============================] - 0s 890us/step - loss: 0.0012 - val_loss: 0.0070\n",
      "Epoch 551/600\n",
      "51/51 [==============================] - 0s 977us/step - loss: 0.0012 - val_loss: 0.0068\n",
      "Epoch 552/600\n",
      "51/51 [==============================] - 0s 938us/step - loss: 0.0012 - val_loss: 0.0071\n",
      "Epoch 553/600\n",
      "51/51 [==============================] - 0s 821us/step - loss: 0.0012 - val_loss: 0.0075\n",
      "Epoch 554/600\n",
      "51/51 [==============================] - 0s 855us/step - loss: 0.0012 - val_loss: 0.0073\n",
      "Epoch 555/600\n",
      "51/51 [==============================] - 0s 821us/step - loss: 0.0012 - val_loss: 0.0066\n",
      "Epoch 556/600\n",
      "51/51 [==============================] - 0s 918us/step - loss: 0.0013 - val_loss: 0.0071\n",
      "Epoch 557/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 919us/step - loss: 0.0012 - val_loss: 0.0068\n",
      "Epoch 558/600\n",
      "51/51 [==============================] - 0s 860us/step - loss: 0.0012 - val_loss: 0.0069\n",
      "Epoch 559/600\n",
      "51/51 [==============================] - 0s 801us/step - loss: 0.0012 - val_loss: 0.0076\n",
      "Epoch 560/600\n",
      "51/51 [==============================] - 0s 821us/step - loss: 0.0012 - val_loss: 0.0071\n",
      "Epoch 561/600\n",
      "51/51 [==============================] - 0s 862us/step - loss: 0.0013 - val_loss: 0.0069\n",
      "Epoch 562/600\n",
      "51/51 [==============================] - 0s 879us/step - loss: 0.0011 - val_loss: 0.0071\n",
      "Epoch 563/600\n",
      "51/51 [==============================] - 0s 801us/step - loss: 0.0011 - val_loss: 0.0071\n",
      "Epoch 564/600\n",
      "51/51 [==============================] - 0s 919us/step - loss: 0.0011 - val_loss: 0.0076\n",
      "Epoch 565/600\n",
      "51/51 [==============================] - 0s 899us/step - loss: 0.0011 - val_loss: 0.0069\n",
      "Epoch 566/600\n",
      "51/51 [==============================] - 0s 782us/step - loss: 0.0012 - val_loss: 0.0070\n",
      "Epoch 567/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0011 - val_loss: 0.0074\n",
      "Epoch 568/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0011 - val_loss: 0.0072\n",
      "Epoch 569/600\n",
      "51/51 [==============================] - 0s 743us/step - loss: 0.0012 - val_loss: 0.0070\n",
      "Epoch 570/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0011 - val_loss: 0.0069\n",
      "Epoch 571/600\n",
      "51/51 [==============================] - 0s 703us/step - loss: 0.0012 - val_loss: 0.0068\n",
      "Epoch 572/600\n",
      "51/51 [==============================] - 0s 703us/step - loss: 0.0011 - val_loss: 0.0072\n",
      "Epoch 573/600\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.0011 - val_loss: 0.0069\n",
      "Epoch 574/600\n",
      "51/51 [==============================] - 0s 703us/step - loss: 0.0011 - val_loss: 0.0069\n",
      "Epoch 575/600\n",
      "51/51 [==============================] - 0s 743us/step - loss: 0.0012 - val_loss: 0.0072\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1db9592cb48>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_model.fit(x=train_data, y=train_labels, batch_size=8, epochs=600,\n",
    "                     validation_data=(test_data, test_labels), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6e2ef44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(train_data[0], train_labels[0])\n",
    "#random_first_predict = regression_model(np.reshape(train_data[0], (1, 13)))\n",
    "#random_first_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b49423a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(train_data[1], train_labels[1])\n",
    "#random_second_predict = regression_model(np.reshape(train_data[1], (1, 13)))\n",
    "#random_second_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "216daefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(train_data[3], train_labels[3])\n",
    "#random_third_predict = regression_model(np.reshape(train_data[3], (1, 13)))\n",
    "#random_third_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b41f4fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_history = pd.DataFrame(regression_model.history.history)\n",
    "model_history.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a6306c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions = regression_model.predict(test_data, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "55083563",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions = model_predictions * 50.\n",
    "test_labels = test_labels * 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f54afec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([19.059694], dtype=float32), array([18.8]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_predictions[1] , test_labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "46ef30f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.models.save_model(regression_model, 'first_regression_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a1d40d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9019607843137255\n"
     ]
    }
   ],
   "source": [
    "errors = 0.0\n",
    "for index in range(len(test_labels)):\n",
    "    #print(model_prediction, test_labels[idx])\n",
    "    if abs(model_predictions[index] - test_labels[index]) > 5.0:\n",
    "        errors += 1\n",
    "print(1. - (errors / len(test_labels)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
